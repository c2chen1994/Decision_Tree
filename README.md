# Decision_Tree
	
	you will implement a simple decision tree algorithm. For simplicity, only discrete features are considered here.

	1 Conditional Entropy 
		Recall that the quality of a split can be measured by the conditional entropy.
	Please read decision tree.py and complete the function “conditional_entropy” (where we use base 2
	for logarithm).

	2 Tree construction
		The building of a decision tree involves growing and pruning. For simplicity, in
	this programming set you are only asked to grow a tree.
	As discussed a tree can be constructed by recursively splitting the nodes if needed, Please read
	decision tree.py and complete the function “split”.

	3 
		Run decision_tree.sh, which will generate decision_tree.json